#### [Common Fund Data Ecosystem (CFDE) Search Portal](https://app.nih-cfde.org/)

The [CFDE search portal](https://app.nih-cfde.org/) provides metadata
search functionality across
[NIH Common Fund data](https://commonfund.nih.gov/) for many
programs. Guided hackathon activities for this round will focus on
accessing, exporting, and working with Human Microbiome Project data
sets, but we encourage participants to explore all of the data available
through the portal!

#### [Extracellular RNA Communication (exRNA)](https://exrna-atlas.org/)

[exRNA](https://exrna-atlas.org/) is small RNA sequences and qPCR-derived exRNA profiles from human and mouse biofluids with over 7,500 entries. The exRNA session will describe two use cases:

1) Exploring RNA Binding Proteins (RBPs) and their associated RNA cargo in various human biofluids and their potential utility as biomarkers, using data from the exRNA Atlas [https://exrna-atlas.org/](https://exrna-atlas.org/).

2) Interrogating other sites across the genome by intersecting exRNA Atlas data with regions of interest using BedGraph files (“data slicing”), and the broader application of this approach to non-RBP sites and other data sets. 

#### [Metabolomics Workbench (MW)](https://www.metabolomicsworkbench.org/)

[Metabolomics Workbench](https://www.metabolomicsworkbench.org/) is an online resource that houses the NIH Common Fund's National Metabolomics Data Repository (NMDR) as well as related databases and resources. The MW provides a platform to deposit metabolomics data to NMDR by researchers across the world, and provides tools to browse, analyze and visualize such data and the related metabolite structures and annotations. Currently, the NMDR has over 2,000 MS and NMR studies covering over 130 different species. The MW metabolite database currently has more than 164,000 molecular structures with the ability to search by text, substructure and m/z values. Tutorials about various aspects of the MW data are provided [here](https://www.metabolomicsworkbench.org/data/tutorials.php).

The Metabolomics Workbench Hackathon Session will provide an introduction to the data as well as structured and unstructured activities.

#### [Signature Commons Library of Integrated Network-Based Cell Signatures (LINCS)](https://maayanlab.cloud/sigcom-lincs/#/SignatureSearch/UpDown)

Millions of transcriptomics samples were generated by the Library of Integrated Network-Based Cellular Signatures [(LINCS) program](https://lincsproject.org/). When these data are processed into searchable signatures along with signatures extracted from [Genotype-Tissue Expression (GTEx)](https://gtexportal.org/home/) and [Gene Expression Omnibus](https://www.ncbi.nlm.nih.gov/geo/), connections between drugs, genes, pathways, and diseases can be illuminated. [SigCom LINCS](https://maayanlab.cloud/sigcom-lincs) is a web-based search engine that serves over 1.5 million gene expression signatures processed, analyzed, and visualized from LINCS, GTEx, and GEO. SigCom LINCS is built from the [Signature Commons framework](https://github.com/MaayanLab/signature-commons), a cloud-agnostic generic platform that can be used to stand up Data Commons with a focus on searchable signatures. SigCom LINCS provides a rapid signature similarity search for mimickers and reversers given sets of up- and down-genes. Additionally, users of SigCom LINCS can perform a metadata search to find and analyze subsets of signatures, and find information about genes and drugs. SigCom LINCS is findable, accessible, interoperable, and reusable (FAIR) compliant with metadata linked to standard ontologies and vocabularies while all data and signatures within SigCom LINCS are available for download and via a [well-documented API](https://maayanlab.cloud/sigcom-lincs/#/API). In summary, SigCom LINCS has the potential to accelerate drug and target discovery in systems pharmacology.

#### [Human Microbiome Project](https://portal.hmpdacc.org/)

[HMP](https://portal.hmpdacc.org/) contains over 31,000 samples from 48 sites on the human body. The HMP session will involve pulling data from the portal and assembling it with Amazon Web Services.
